import cv2
import mediapipe as mp
import numpy as np
import os

# ==========================================
# ì„¤ì •
# ==========================================
TARGET_CLASS = "ì§‘"
USER_NAME = "hb"
SAVE_DIR = "word_data"

SEQ_LEN = 15
VALID_Y_LIMIT = 0.9

FACE_LMS = [1, 33, 263, 61, 291]  # ì–¼êµ´ 5í¬ì¸íŠ¸

# ==========================================
# ë””ë ‰í† ë¦¬ ìƒì„±
# ==========================================
os.makedirs(SAVE_DIR, exist_ok=True)

# ==========================================
# MediaPipe Holistic
# ==========================================
mp_holistic = mp.solutions.holistic
holistic = mp_holistic.Holistic(
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5
)
mp_drawing = mp.solutions.drawing_utils

# ==========================================
# ì •ê·œí™” í•¨ìˆ˜
# ==========================================
def normalize_features(left_hand, right_hand, face):
    """left_hand / right_hand ê°€ Noneì´ë©´ ìë™ìœ¼ë¡œ 0ìœ¼ë¡œ ì±„ì›€."""
    if face is None:
        return np.zeros(141, dtype=np.float32)

    nose = face[0]
    face_width = np.linalg.norm(face[1] - face[2])
    if face_width < 1e-6:
        face_width = 1e-6

    def norm(x):
        return (x - nose) / face_width

    # ì†ì´ Noneì´ë©´ 0ì±„ì›€
    if left_hand is None:
        left_hand = np.zeros((21, 3))
    else:
        left_hand = norm(left_hand)

    if right_hand is None:
        right_hand = np.zeros((21, 3))
    else:
        right_hand = norm(right_hand)

    face = norm(face)

    return np.concatenate([
        left_hand.flatten(),
        right_hand.flatten(),
        face.flatten()
    ], axis=0)


# ==========================================
# ì›¹ìº  ì¤€ë¹„
# ==========================================
cap = cv2.VideoCapture(0)

data_buffer = []
all_sequences = []
is_recording = False

last_face = None  # ì–¼êµ´ì´ ê°€ë ¤ì§ˆ ê²½ìš° ëŒ€ë¹„ ì €ì¥

print(f"=== ìˆ˜ì–´ ë‹¨ì–´ [{TARGET_CLASS}] ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ ===")
print("âœ” í•œ ì†ë§Œ ìˆì–´ë„ ë…¹í™”ë©ë‹ˆë‹¤.")
print("âœ” ë‘ ì†ì´ ëª¨ë‘ ì‚¬ë¼ì§€ë©´ ì‹œí€€ìŠ¤ê°€ ì €ì¥ë©ë‹ˆë‹¤.")
print("âœ” ì–¼êµ´ì´ ì ê¹ ê°€ë ¤ì ¸ë„ ë…¹í™”ê°€ ëŠê¸°ì§€ ì•ŠìŠµë‹ˆë‹¤.")
print("ì¢…ë£Œ: q")

# ==========================================
# ë©”ì¸ ë£¨í”„
# ==========================================
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    frame = cv2.flip(frame, 1)
    h, w, _ = frame.shape

    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = holistic.process(rgb)

    # ë…¹í™” ë¼ì¸
    cv2.line(frame, (0, int(h * VALID_Y_LIMIT)), (w, int(h * VALID_Y_LIMIT)), (0, 255, 0), 2)

    # ëœë“œë§ˆí¬ ì°¸ì¡°
    left_lms = results.left_hand_landmarks
    right_lms = results.right_hand_landmarks
    face_lms = results.face_landmarks

    # ===== ì–¼êµ´ ì²˜ë¦¬ (ê°€ë ¤ì ¸ë„ ëŠê¸°ì§€ ì•Šë„ë¡ last_face ìœ ì§€) =====
    if face_lms is not None:
        try:
            face = np.array([
                [face_lms.landmark[i].x,
                 face_lms.landmark[i].y,
                 face_lms.landmark[i].z] 
                for i in FACE_LMS
            ])
            last_face = face  # ì •ìƒ ì—…ë°ì´íŠ¸
        except:
            face = last_face if last_face is not None else None
    else:
        face = last_face if last_face is not None else None

    # ===== ì† ì¸ì‹ ì—¬ë¶€ =====
    left_present = left_lms is not None
    right_present = right_lms is not None
    hand_present = left_present or right_present

    # ===== ë…¹í™” ê°€ëŠ¥í•œ í”„ë ˆì„ì¸ì§€ =====
    valid_frame = False

    if face is not None and hand_present:

        # ì† ì¢Œí‘œ ì¶”ì¶œ
        left_hand = np.array([[lm.x, lm.y, lm.z] for lm in left_lms.landmark]) if left_present else None
        right_hand = np.array([[lm.x, lm.y, lm.z] for lm in right_lms.landmark]) if right_present else None

        # ê¸°ì¤€ ì†ëª© yì¢Œí‘œ (ì™¼ì† > ì˜¤ë¥¸ì† ìˆœ)
        if left_present:
            wrist_y = left_hand[0, 1]
        else:
            wrist_y = right_hand[0, 1]

        # ---- ë…¹í™” ì¡°ê±´ ----
        if wrist_y < VALID_Y_LIMIT:
            valid_frame = True
            vec = normalize_features(left_hand, right_hand, face)
            data_buffer.append(vec)
            is_recording = True

            cv2.circle(frame, (30, 30), 15, (0, 0, 255), -1)
            cv2.putText(frame, f"REC ({len(data_buffer)})", (55, 40),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)

        # ---- ëœë“œë§ˆí¬ í‘œì‹œ ----
        if left_present:
            mp_drawing.draw_landmarks(frame, left_lms, mp_holistic.HAND_CONNECTIONS)
        if right_present:
            mp_drawing.draw_landmarks(frame, right_lms, mp_holistic.HAND_CONNECTIONS)
        if face_lms:
            mp_drawing.draw_landmarks(frame, face_lms, mp_holistic.FACEMESH_TESSELATION)

    # ===== ì €ì¥ ì¡°ê±´: ë…¹í™” ì¤‘ + ë‘ ì† ëª¨ë‘ ì—†ìŒ =====
    if is_recording and not hand_present:

        if len(data_buffer) >= SEQ_LEN:
            for i in range(len(data_buffer) - SEQ_LEN + 1):
                all_sequences.append(data_buffer[i:i+SEQ_LEN])
            print(f"âœ… ì‹œí€€ìŠ¤ ì €ì¥ë¨ (ëˆ„ì : {len(all_sequences)})")
        else:
            print("âš ï¸ ë™ì‘ ë„ˆë¬´ ì§§ì•„ì„œ ë²„ë ¤ì§")

        data_buffer = []
        is_recording = False

    # UI í‘œì‹œ
    cv2.putText(frame, f"Class: {TARGET_CLASS}", (10, h - 20),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)
    cv2.putText(frame, f"Collected: {len(all_sequences)}", (w - 200, h - 20),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,0), 2)

    cv2.imshow("Collector", frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()

# ==========================================
# ì €ì¥
# ==========================================
if all_sequences:
    filename = f"{TARGET_CLASS}_{USER_NAME}.npy"
    np.save(os.path.join(SAVE_DIR, filename), np.array(all_sequences))
    print(f"\nğŸ‰ ì €ì¥ ì™„ë£Œ â†’ {SAVE_DIR}/{filename}")
else:
    print("\nâŒ ìˆ˜ì§‘ëœ ë°ì´í„° ì—†ìŒ")
